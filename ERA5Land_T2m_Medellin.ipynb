{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ERA5‑Land · Temperatura del aire a 2 m (t2m) en puntos de Colombia\n",
        "\n",
        "Este cuaderno descarga **temperatura del aire a 2 m** (t2m) desde **ERA5‑Land** (dataset horario) para uno o varios puntos,\n",
        "y construye un **DataFrame** con las series en **°C**. Puedes elegir **agregación diaria** o **horaria**.\n",
        "\n",
        "**Notas**\n",
        "- ERA5‑Land es un **reanálisis** (malla ~9 km). No es satélite directo. Ideal para series continuas.\n",
        "- El tiempo de ERA5 está en **UTC**; abajo añadimos también columna en hora local **America/Bogota**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<p>To authorize access needed by Earth Engine, open the following\n",
              "        URL in a web browser and follow the instructions:</p>\n",
              "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/drive%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=PMxRZAcNJh5fwHPE4dEBPXq6s_t_Sxb-2UNLS0itTXU&tc=d1gKkpzhbw04HzIo8Cc1eji8AzpxSYW92H-8amZSf34&cc=C-FB70lru9DTjyHFNs8TLWTGQq2JcAF4yyPwtMVzsXM>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/drive%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=PMxRZAcNJh5fwHPE4dEBPXq6s_t_Sxb-2UNLS0itTXU&tc=d1gKkpzhbw04HzIo8Cc1eji8AzpxSYW92H-8amZSf34&cc=C-FB70lru9DTjyHFNs8TLWTGQq2JcAF4yyPwtMVzsXM</a></p>\n",
              "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "# Instalar y autenticar Google Earth Engine (solo la primera vez)\n",
        "!pip -q install earthengine-api geemap pandas\n",
        "import ee, geemap\n",
        "ee.Authenticate()  # sigue el link, autoriza, pega el token\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import ee\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ee.Initialize()  # ← Asegúrate de inicializar Earth Engine\n",
        "\n",
        "# ---------------- Configuración ----------------\n",
        "LOCATIONS = [\n",
        "    {\"name\": \"CEN-TRAF\", \"lat\": 6.252306, \"lon\": -75.568852},\n",
        "    {\"name\": \"ITA-CJUS\", \"lat\": 6.186118, \"lon\": -75.597457},\n",
        "    {\"name\": \"GIR-EPM\",  \"lat\": 6.373513, \"lon\": -75.448027},\n",
        "    {\"name\": \"MED-FISC\", \"lat\": 6.267655, \"lon\": -75.574471},\n",
        "]\n",
        "\n",
        "DATE_START = \"2021-01-01\"  # inclusive\n",
        "DATE_END   = \"2025-02-28\"  # exclusiva en filterDate (usa +1 día si quieres incluir el fin exacto)\n",
        "\n",
        "# \"hourly\" para datos por hora, \"daily\" para promedio diario\n",
        "AGG = \"hourly\"  # \"daily\" o \"hourly\"\n",
        "\n",
        "# ------------------------------------------------\n",
        "COL = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\").filterDate(DATE_START, DATE_END)\n",
        "\n",
        "def hourly_ic(ic, band=\"temperature_2m\"):\n",
        "    def to_celsius(img):\n",
        "        t = img.select([band]).subtract(273.15).rename(\"t2m_c\")\n",
        "        return t.set({\n",
        "            \"datetime_utc\": img.date().format(\"YYYY-MM-dd HH:mm\"),\n",
        "            \"system:time_start\": img.get(\"system:time_start\")\n",
        "        })\n",
        "    return ic.map(to_celsius)\n",
        "\n",
        "def daily_means_from_hourly(ic, band=\"temperature_2m\"):\n",
        "    start = ee.Date(DATE_START)\n",
        "    end   = ee.Date(DATE_END)\n",
        "    n_days = end.difference(start, \"day\").toInt()\n",
        "\n",
        "    def day_img(day_idx):\n",
        "        d = start.advance(day_idx, \"day\")\n",
        "        d1 = d.advance(1, \"day\")\n",
        "        daily = ic.filterDate(d, d1).select([band]).mean().subtract(273.15).rename(\"t2m_c\")\n",
        "        return daily.set({\n",
        "            \"date\": d.format(\"YYYY-MM-dd\"),\n",
        "            \"system:time_start\": d.millis()\n",
        "        })\n",
        "    days = ee.List.sequence(0, n_days.subtract(1))\n",
        "    return ee.ImageCollection(days.map(day_img))\n",
        "\n",
        "ic_use = daily_means_from_hourly(COL) if AGG == \"daily\" else hourly_ic(COL)\n",
        "\n",
        "# ---- Puntos ----\n",
        "features = []\n",
        "for p in LOCATIONS:\n",
        "    pt = ee.Geometry.Point([p[\"lon\"], p[\"lat\"]])\n",
        "    features.append(ee.Feature(pt, {\"name\": p[\"name\"], \"lat\": p[\"lat\"], \"lon\": p[\"lon\"]}))\n",
        "points_fc = ee.FeatureCollection(features)\n",
        "\n",
        "# ---- Muestreo en puntos para cada imagen ----\n",
        "def sample_points(img):\n",
        "    sampled = img.sampleRegions(\n",
        "        collection=points_fc,\n",
        "        properties=[\"name\", \"lat\", \"lon\"],\n",
        "        scale=10000,   # ERA5-Land ~9 km\n",
        "        geometries=False\n",
        "    )\n",
        "    return sampled.map(lambda f: f.set({\n",
        "        \"date\": img.get(\"date\"),\n",
        "        \"datetime_utc\": img.get(\"datetime_utc\"),\n",
        "        \"time_start\": img.get(\"system:time_start\")\n",
        "    }))\n",
        "\n",
        "fc = ic_use.map(sample_points).flatten()\n",
        "\n",
        "# ---- A pandas ----\n",
        "_EXPECTED_COLS = [\"name\", \"lat\", \"lon\", \"t2m_c\", \"date\", \"datetime_utc\", \"time_start\"]\n",
        "\n",
        "def fc_to_pandas(fc: ee.FeatureCollection, properties=None, limit=100000):\n",
        "    size = int(fc.size().getInfo())\n",
        "    size = min(size, limit)\n",
        "    if size == 0:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if properties is None:\n",
        "        first_props = ee.Feature(fc.first()).toDictionary().keys().getInfo()\n",
        "        properties = [c for c in _EXPECTED_COLS if c in first_props] or first_props\n",
        "\n",
        "    flist = fc.limit(size).toList(size)\n",
        "    dicts = flist.map(lambda f: ee.Feature(f).toDictionary(properties))\n",
        "    data = dicts.getInfo()  # ⚠️ Si es muy grande, usa Export.table.toDrive\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df = fc_to_pandas(\n",
        "    fc,\n",
        "    properties=[\"name\", \"lat\", \"lon\", \"t2m_c\", \"date\", \"datetime_utc\", \"time_start\"],\n",
        ")\n",
        "\n",
        "# ===== Normalización de tiempos (una sola vez) =====\n",
        "# Preferimos datetime_utc (string) → UTC; si no, 'date'; si no, 'time_start' (ms)\n",
        "if \"datetime_utc\" in df.columns and df[\"datetime_utc\"].notna().any():\n",
        "    dt_utc = pd.to_datetime(df[\"datetime_utc\"], format=\"%Y-%m-%d %H:%M\", errors=\"coerce\", utc=True)\n",
        "elif \"date\" in df.columns and df[\"date\"].notna().any():\n",
        "    dt_utc = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\", errors=\"coerce\", utc=True)\n",
        "else:\n",
        "    # fallback a time_start en ms\n",
        "    dt_utc = pd.to_datetime(df[\"time_start\"], unit=\"ms\", utc=True)\n",
        "\n",
        "df[\"datetime_utc\"] = dt_utc\n",
        "df[\"datetime_bogota\"] = df[\"datetime_utc\"].dt.tz_convert(\"America/Bogota\")\n",
        "\n",
        "# Filas ordenadas y columnas básicas\n",
        "df = df[[\"name\",\"lat\",\"lon\",\"t2m_c\",\"datetime_utc\",\"datetime_bogota\"]].dropna(subset=[\"datetime_utc\"])\n",
        "df = df.sort_values([\"name\",\"datetime_utc\"]).reset_index(drop=True)\n",
        "\n",
        "# ===== Pivot a formato ancho: una columna por punto =====\n",
        "# Si hay duplicados por (name, datetime_utc), usamos la media.\n",
        "wide_temp = (\n",
        "    df.pivot_table(index=\"datetime_utc\", columns=\"name\", values=\"t2m_c\", aggfunc=\"mean\")\n",
        "    .sort_index()\n",
        ")\n",
        "\n",
        "# Añadimos columnas de tiempo al principio (UTC + Bogotá)\n",
        "df_out = wide_temp.copy()\n",
        "df_out.insert(0, \"datetime_bogota\", df_out.index.tz_convert(\"America/Bogota\"))\n",
        "df_out.insert(0, \"datetime_utc\", df_out.index)\n",
        "\n",
        "# (Opcional) convertir timestamps a ISO string para CSV \"limpio\"\n",
        "df_out[\"datetime_utc\"] = df_out[\"datetime_utc\"].dt.strftime(\"%Y-%m-%d %H:%M:%S%z\").str.replace(r\"(\\+00:00)$\",\"Z\", regex=True)\n",
        "df_out[\"datetime_bogota\"] = pd.to_datetime(df_out[\"datetime_bogota\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
        "\n",
        "# ===== Guardar a CSV =====\n",
        "out_dir = Path(\"data/raw/era5\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "# Si quieres que DATE_END sea inclusivo en el nombre, ajusta aquí.\n",
        "fname = f\"era5_t2m_{AGG}_{DATE_START}_{DATE_END}.csv\"\n",
        "out_path = out_dir / fname\n",
        "df_out.to_csv(out_path, index=False)\n",
        "print(f\"CSV guardado en: {out_path.resolve()}\")\n",
        "\n",
        "# (Opcional) vista rápida\n",
        "print(df_out.head(3))\n",
        "print(\"shape:\", df_out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "28049e3d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lanzada: era5_so2_noTurb_hourly_202101 | id: GV6CZZWC4QONEJXOS5ZVQVMT | 2021-01-01 → 2021-02-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202102 | id: J52RYAJ34YFKXFZOF2XF7VFZ | 2021-02-01 → 2021-03-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202103 | id: P3X2UNVOMFSQABRD2ZTA37YS | 2021-03-01 → 2021-04-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202104 | id: CYCSNET2UGYT7AS7C7Z2X4WB | 2021-04-01 → 2021-05-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202105 | id: JC73ZGH534MDRLBFKSCWCKZA | 2021-05-01 → 2021-06-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202106 | id: MMTYOIY5DPAPNROHLFPGHGRL | 2021-06-01 → 2021-07-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202107 | id: OB3ZH266F7NVO7JE5PXCUJT5 | 2021-07-01 → 2021-08-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202108 | id: STGTWDDWXUKHJBTTDGJEOYMD | 2021-08-01 → 2021-09-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202109 | id: PIWMURUCBQMWX4RYOUWIE4LI | 2021-09-01 → 2021-10-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202110 | id: GK7FHQWNNPDN5Q4CHKQDAUMD | 2021-10-01 → 2021-11-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202111 | id: LMXGVGY5XJUKM4ME3EZTCFE3 | 2021-11-01 → 2021-12-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202112 | id: R5WV3AIVWCJUQ5TLW4IE7UJD | 2021-12-01 → 2022-01-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202201 | id: 56NUDHDDALQUQP4IF6W4CSI3 | 2022-01-01 → 2022-02-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202202 | id: ZJVH2OHE7RSU7ZL2Z7GOAOEE | 2022-02-01 → 2022-03-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202203 | id: 5YXNGJHF7O3P3PF6PM2T73GB | 2022-03-01 → 2022-04-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202204 | id: V4NCBAXV3IFQSBP77ZJAFZAI | 2022-04-01 → 2022-05-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202205 | id: GXJVS3LXAKWFGJ37BACQ3ZYB | 2022-05-01 → 2022-06-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202206 | id: 6SEU6GZOOV4UK6JPIWKELA72 | 2022-06-01 → 2022-07-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202207 | id: DNONYB7T763QJ4KCPT7VEQCD | 2022-07-01 → 2022-08-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202208 | id: WUROALGDPXSO6CD3LWKAFDWM | 2022-08-01 → 2022-09-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202209 | id: 6ZQ72Y3PHTDUBB5WR4JNPTWX | 2022-09-01 → 2022-10-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202210 | id: 5AXPCBPKJIB2XNZCIAGGYFZC | 2022-10-01 → 2022-11-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202211 | id: U3LETD3JUADQPZSJHWRGBK7G | 2022-11-01 → 2022-12-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202212 | id: OHWXCZE4JH32GZPAFGQ7FX62 | 2022-12-01 → 2023-01-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202301 | id: O257FARRZXMTS25M5SU3EDOA | 2023-01-01 → 2023-02-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202302 | id: BP3FXBHF2A2HIL4H4RY72WFF | 2023-02-01 → 2023-03-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202303 | id: WTAN4G5U34LR47HPUDCQJNTK | 2023-03-01 → 2023-04-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202304 | id: LMNH2KPQYHLKGWQBL77V5FPV | 2023-04-01 → 2023-05-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202305 | id: HXDSKMEX5EL6AZYU2DOQ6NKB | 2023-05-01 → 2023-06-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202306 | id: 67BR636UHBNWBPWPT7BGVLIJ | 2023-06-01 → 2023-07-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202307 | id: S6D7BLHGRPLJLSSXEKXGY5CR | 2023-07-01 → 2023-08-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202308 | id: AZHJ4FNBC4AEPQUHLH57B25F | 2023-08-01 → 2023-09-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202309 | id: A3ZVXI2HMLAGXP2YBQU6GOBG | 2023-09-01 → 2023-10-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202310 | id: RKP4XV3SFFCMUUFDXHXTUI56 | 2023-10-01 → 2023-11-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202311 | id: NJYGJMTGTGHMPTLTDBCY7AYF | 2023-11-01 → 2023-12-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202312 | id: LKNPCCKBZ6LIMTAVHRCWMQAE | 2023-12-01 → 2024-01-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202401 | id: 6XGNRVR4NA44RLKI4EBNDV7N | 2024-01-01 → 2024-02-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202402 | id: 3ZMQOQ5ELP23CFCTIDHXCCCK | 2024-02-01 → 2024-03-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202403 | id: UTMWHLBXBY2WOXEJQTYSQ4NN | 2024-03-01 → 2024-04-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202404 | id: 4X56CMCRB6EKWHOWK275YO7A | 2024-04-01 → 2024-05-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202405 | id: HHQZUNV7O5LVDM5JIXNEQIE5 | 2024-05-01 → 2024-06-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202406 | id: SSEA4SRRUYG6Y5ACB7SSMQ2E | 2024-06-01 → 2024-07-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202407 | id: VACWNJQIAH2XECTNLJYYMSLA | 2024-07-01 → 2024-08-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202408 | id: 4OQ4KQJPURXA3E4VBCCM5DIQ | 2024-08-01 → 2024-09-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202409 | id: EWWHGINGVPL4BQPOGDPUHCJO | 2024-09-01 → 2024-10-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202410 | id: L55XNGFXIVDKCSVI6FZYFC6Y | 2024-10-01 → 2024-11-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202411 | id: ACFA33LV27HE6ANCJKUUZIGK | 2024-11-01 → 2024-12-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202412 | id: 7S2BYGMXUIAZZOB67MO3GMNG | 2024-12-01 → 2025-01-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202501 | id: WPMPFXRHSVTDYIKOX37VMLET | 2025-01-01 → 2025-02-01\n",
            "Lanzada: era5_so2_noTurb_hourly_202502 | id: 5OR6V7HXDJCSUVG63RQLI7QN | 2025-02-01 → 2025-03-01\n",
            "Tasks lanzadas: 50\n"
          ]
        }
      ],
      "source": [
        "import ee, pandas as pd\n",
        "import math\n",
        "ee.Initialize(project=None)\n",
        "\n",
        "# ================== CONFIG ==================\n",
        "LOCATIONS = [\n",
        "    {\"name\": \"CEN-TRAF\", \"lat\": 6.252306, \"lon\": -75.568852},\n",
        "    {\"name\": \"ITA-CJUS\", \"lat\": 6.186118, \"lon\": -75.597457},\n",
        "    {\"name\": \"GIR-EPM\",  \"lat\": 6.373513, \"lon\": -75.448027},\n",
        "    {\"name\": \"MED-FISC\", \"lat\": 6.267655, \"lon\": -75.574471},\n",
        "]\n",
        "DATE_START   = \"2021-01-01\"\n",
        "DATE_END_EXC = \"2025-03-01\"   # fin exclusivo\n",
        "DRIVE_FOLDER = \"era5_exports_so2_no_turb\"  # <- nueva carpeta para esta corrida\n",
        "CHUNK_FREQ   = \"MS\"           # mensual\n",
        "\n",
        "COL = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\").filterDate(DATE_START, DATE_END_EXC)\n",
        "\n",
        "# --- Imagen con bandas convertidas y DERIVADAS (sin turbulencia: NO sshf/slhf) ---\n",
        "def to_features(img):\n",
        "    # Temperatura y humedad (°C)\n",
        "    t2m  = img.select('temperature_2m').subtract(273.15).rename('t2m_c')\n",
        "    td2m = img.select('dewpoint_temperature_2m').subtract(273.15).rename('td2m_c')\n",
        "\n",
        "    # Presión (hPa)\n",
        "    sp   = img.select('surface_pressure').divide(100).rename('sp_hpa')\n",
        "\n",
        "    # Viento (m/s) y dirección (grados 0..360)\n",
        "    u10  = img.select('u_component_of_wind_10m').rename('u10')\n",
        "    v10  = img.select('v_component_of_wind_10m').rename('v10')\n",
        "    ws   = u10.hypot(v10).rename('wind_speed')\n",
        "\n",
        "    # ⬇️ FIX: usa math.pi (float) o ee.Number(180).divide(math.pi)\n",
        "    wind_dir = u10.atan2(v10).multiply(180.0 / math.pi).rename('wind_dir_deg')\n",
        "    wind_dir = wind_dir.where(wind_dir.lt(0), wind_dir.add(360))\n",
        "\n",
        "    # Precipitación horaria (m -> mm/h)\n",
        "    tp_h = img.select('total_precipitation_hourly').multiply(1000).rename('tp_mm_h')\n",
        "\n",
        "    # Radiación (J/m²·h -> W/m²)\n",
        "    ssrdh  = img.select('surface_solar_radiation_downwards_hourly').divide(3600).rename('ssrd_wm2')\n",
        "    ssrnet = img.select('surface_net_solar_radiation_hourly').divide(3600).rename('ssrnet_wm2')\n",
        "    strdh  = img.select('surface_thermal_radiation_downwards_hourly').divide(3600).rename('strd_wm2')\n",
        "    strnet = img.select('surface_net_thermal_radiation_hourly').divide(3600).rename('strnet_wm2')\n",
        "\n",
        "    # Humedad relativa (%)\n",
        "    a = ee.Number(17.625); b = ee.Number(243.04)\n",
        "    rh = (td2m.expression(\n",
        "        '100 * exp((a*TD)/(b+TD) - (a*T)/(b+T))',\n",
        "        {'a': a, 'b': b, 'TD': td2m, 'T': t2m}\n",
        "    ).rename('rh_percent')).clamp(0, 100)\n",
        "\n",
        "    return (t2m.addBands([td2m, rh,\n",
        "                          u10, v10, ws, wind_dir,\n",
        "                          sp,\n",
        "                          tp_h,\n",
        "                          ssrdh, ssrnet, strdh, strnet])\n",
        "              .set({\n",
        "                  'datetime_utc': img.date().format('YYYY-MM-dd HH:mm'),\n",
        "                  'system:time_start': img.get('system:time_start')\n",
        "              }))\n",
        "\n",
        "ic_feats = COL.map(to_features)\n",
        "\n",
        "# Puntos\n",
        "features = [ee.Feature(ee.Geometry.Point([p[\"lon\"], p[\"lat\"]]), p) for p in LOCATIONS]\n",
        "points_fc = ee.FeatureCollection(features)\n",
        "\n",
        "def sample_points(img):\n",
        "    props = [\"name\", \"lat\", \"lon\"]\n",
        "    sampled = img.sampleRegions(collection=points_fc, properties=props, scale=10000, geometries=False)\n",
        "    return sampled.map(lambda f: f.set({\n",
        "        'datetime_utc': img.get('datetime_utc'),\n",
        "        'time_start': img.get('system:time_start')\n",
        "    }))\n",
        "\n",
        "def export_chunks_to_drive():\n",
        "    edges = pd.date_range(DATE_START, DATE_END_EXC, freq=CHUNK_FREQ)\n",
        "    tasks = []\n",
        "    selectors = [\n",
        "        \"name\",\"lat\",\"lon\",\n",
        "        # thermo & humidity\n",
        "        \"t2m_c\",\"td2m_c\",\"rh_percent\",\n",
        "        # wind\n",
        "        \"u10\",\"v10\",\"wind_speed\",\"wind_dir_deg\",\n",
        "        # pressure\n",
        "        \"sp_hpa\",\n",
        "        # precip & radiation\n",
        "        \"tp_mm_h\",\"ssrd_wm2\",\"ssrnet_wm2\",\"strd_wm2\",\"strnet_wm2\",\n",
        "        # timestamps\n",
        "        \"datetime_utc\",\"time_start\"\n",
        "    ]\n",
        "    for i in range(len(edges)-1):\n",
        "        s = edges[i].strftime(\"%Y-%m-%d\")\n",
        "        e = edges[i+1].strftime(\"%Y-%m-%d\")\n",
        "        fc = ic_feats.filterDate(s, e).map(sample_points).flatten()\n",
        "        desc  = f\"era5_so2_noTurb_hourly_{edges[i].strftime('%Y%m')}\"\n",
        "        fname = f\"era5_so2_noTurb_hourly_{s}_to_{e}\"\n",
        "        task = ee.batch.Export.table.toDrive(\n",
        "            collection=fc,\n",
        "            description=desc,\n",
        "            folder=DRIVE_FOLDER,\n",
        "            fileNamePrefix=fname,\n",
        "            fileFormat=\"CSV\",\n",
        "            selectors=selectors\n",
        "        )\n",
        "        task.start()\n",
        "        tasks.append((desc, task.id))\n",
        "        print(f\"Lanzada: {desc} | id: {task.id} | {s} → {e}\")\n",
        "    return tasks\n",
        "\n",
        "tasks = export_chunks_to_drive()\n",
        "print(\"Tasks lanzadas:\", len(tasks))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4492a9d6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task lanzada: era5_so2_noTurb_hourly_EXTRA_20250301T0000__20250301T0500\n"
          ]
        }
      ],
      "source": [
        "# === Exportar 5 horas \"faltantes\" como un archivo extra ===\n",
        "import ee, pandas as pd, math\n",
        "ee.Initialize(project=None)\n",
        "\n",
        "# ===== Ajusta estas dos marcas en UTC (fin es exclusivo) =====\n",
        "EXTRA_START_UTC = \"2025-03-01T00:00\"   # <-- ejemplo\n",
        "EXTRA_END_UTC   = \"2025-03-01T05:00\"   # <-- ejemplo (5 horas)\n",
        "\n",
        "# PUNTOS (mismo set que usaste)\n",
        "LOCATIONS = [\n",
        "    {\"name\": \"CEN-TRAF\", \"lat\": 6.252306, \"lon\": -75.568852},\n",
        "    {\"name\": \"ITA-CJUS\", \"lat\": 6.186118, \"lon\": -75.597457},\n",
        "    {\"name\": \"GIR-EPM\",  \"lat\": 6.373513, \"lon\": -75.448027},\n",
        "    {\"name\": \"MED-FISC\", \"lat\": 6.267655, \"lon\": -75.574471},\n",
        "]\n",
        "\n",
        "# Carpeta de Drive donde dejaste los mensuales\n",
        "DRIVE_FOLDER = \"era5_exports_so2_no_turb\"  # la misma que ya usaste\n",
        "\n",
        "# Colección\n",
        "COL = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\").filterDate(EXTRA_START_UTC, EXTRA_END_UTC)\n",
        "\n",
        "def to_features(img):\n",
        "    t2m  = img.select('temperature_2m').subtract(273.15).rename('t2m_c')\n",
        "    td2m = img.select('dewpoint_temperature_2m').subtract(273.15).rename('td2m_c')\n",
        "    sp   = img.select('surface_pressure').divide(100).rename('sp_hpa')\n",
        "    u10  = img.select('u_component_of_wind_10m').rename('u10')\n",
        "    v10  = img.select('v_component_of_wind_10m').rename('v10')\n",
        "    ws   = u10.hypot(v10).rename('wind_speed')\n",
        "    wind_dir = u10.atan2(v10).multiply(180.0 / math.pi).rename('wind_dir_deg')\n",
        "    wind_dir = wind_dir.where(wind_dir.lt(0), wind_dir.add(360))\n",
        "    tp_h  = img.select('total_precipitation_hourly').multiply(1000).rename('tp_mm_h')\n",
        "    ssrdh = img.select('surface_solar_radiation_downwards_hourly').divide(3600).rename('ssrd_wm2')\n",
        "    ssrnet = img.select('surface_net_solar_radiation_hourly').divide(3600).rename('ssrnet_wm2')\n",
        "    strdh = img.select('surface_thermal_radiation_downwards_hourly').divide(3600).rename('strd_wm2')\n",
        "    strnet = img.select('surface_net_thermal_radiation_hourly').divide(3600).rename('strnet_wm2')\n",
        "    a = ee.Number(17.625); b = ee.Number(243.04)\n",
        "    rh = (td2m.expression(\n",
        "        '100 * exp((a*TD)/(b+TD) - (a*T)/(b+T))',\n",
        "        {'a': a, 'b': b, 'TD': td2m, 'T': t2m}\n",
        "    ).rename('rh_percent')).clamp(0, 100)\n",
        "\n",
        "    return (t2m.addBands([td2m, rh, u10, v10, ws, wind_dir, sp, tp_h, ssrdh, ssrnet, strdh, strnet])\n",
        "              .set({'datetime_utc': img.date().format('YYYY-MM-dd HH:mm'),\n",
        "                    'system:time_start': img.get('system:time_start')}))\n",
        "\n",
        "ic_feats = COL.map(to_features)\n",
        "\n",
        "# Puntos\n",
        "features = [ee.Feature(ee.Geometry.Point([p[\"lon\"], p[\"lat\"]]), p) for p in LOCATIONS]\n",
        "points_fc = ee.FeatureCollection(features)\n",
        "\n",
        "def sample_points(img):\n",
        "    props = [\"name\",\"lat\",\"lon\"]\n",
        "    sampled = img.sampleRegions(collection=points_fc, properties=props, scale=10000, geometries=False)\n",
        "    return sampled.map(lambda f: f.set({\n",
        "        'datetime_utc': img.get('datetime_utc'),\n",
        "        'time_start': img.get('system:time_start')\n",
        "    }))\n",
        "\n",
        "selectors = [\n",
        "    \"name\",\"lat\",\"lon\",\n",
        "    \"t2m_c\",\"td2m_c\",\"rh_percent\",\n",
        "    \"u10\",\"v10\",\"wind_speed\",\"wind_dir_deg\",\n",
        "    \"sp_hpa\",\n",
        "    \"tp_mm_h\",\"ssrd_wm2\",\"ssrnet_wm2\",\"strd_wm2\",\"strnet_wm2\",\n",
        "    \"datetime_utc\",\"time_start\"\n",
        "]\n",
        "\n",
        "# Export único del rango corto\n",
        "fc_extra = ic_feats.map(sample_points).flatten()\n",
        "desc  = f\"era5_so2_noTurb_hourly_EXTRA_{EXTRA_START_UTC.replace(':','').replace('-','')}__{EXTRA_END_UTC.replace(':','').replace('-','')}\"\n",
        "fname = f\"era5_so2_noTurb_hourly_{EXTRA_START_UTC}_to_{EXTRA_END_UTC}\"\n",
        "\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=fc_extra,\n",
        "    description=desc,\n",
        "    folder=DRIVE_FOLDER,\n",
        "    fileNamePrefix=fname,\n",
        "    fileFormat=\"CSV\",\n",
        "    selectors=selectors\n",
        ")\n",
        "task.start()\n",
        "print(\"Task lanzada:\", desc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4c176fd5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔ CSV generado: C:\\Maestria\\Trabajo de grado\\repositorio\\data\\raw\\era5\\era5_SO2_hourly_custom_header_2021-01-01_2025-02-28.csv\n",
            "shape: (36485, 24) | filas (horas) x columnas (estación*variable)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ========= CONFIG =========\n",
        "# Carpeta donde guardaste TODOS los CSV descargados de Drive (mensuales)\n",
        "IN_DIR  = Path(\"era5_exports\")   # <-- cámbiala si aplica\n",
        "OUT_DIR = Path(\"data/raw/era5\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Estaciones en el orden exacto que quieres en el header final\n",
        "# Nota: si tus CSV tienen \"GIR-EPM\" pero quieres \"V-GIR-EPM\" en el encabezado, lo renombramos.\n",
        "stations_order_final = [\"V-GIR-EPM\", \"MED-FISC\", \"CEN-TRAF\", \"ITA-CJUS\"]\n",
        "\n",
        "# Renombrado de estaciones (como vienen en los CSV -> como quieres en el header)\n",
        "STATION_RENAME = {\n",
        "    \"GIR-EPM\": \"V-GIR-EPM\",\n",
        "    # deja idénticas las demás si coinciden\n",
        "    \"MED-FISC\": \"MED-FISC\",\n",
        "    \"CEN-TRAF\": \"CEN-TRAF\",\n",
        "    \"ITA-CJUS\": \"ITA-CJUS\",\n",
        "}\n",
        "\n",
        "# Variables que exportaste (sin turbulencia)\n",
        "# y cómo se llaman en tu header deseado (nomenclatura del usuario)\n",
        "labels_order = [\"DViento_SSR\",\"HAire10_SSR\",\"PLiquida_SSR\",\"P_SSR\",\"TAire10_SSR\",\"VViento_SSR\"]\n",
        "label_to_col = {\n",
        "    \"DViento_SSR\": \"wind_dir_deg\",   # grados (0..360)\n",
        "    \"HAire10_SSR\": \"rh_percent\",     # %\n",
        "    \"PLiquida_SSR\": \"tp_mm_h\",       # mm/h\n",
        "    \"P_SSR\":       \"sp_hpa\",         # hPa\n",
        "    \"TAire10_SSR\": \"t2m_c\",          # °C\n",
        "    \"VViento_SSR\": \"wind_speed\",     # m/s\n",
        "}\n",
        "VARS = list(label_to_col.values())\n",
        "\n",
        "# ========= 1) LEER Y CONCATENAR (LARGO) =========\n",
        "files = sorted([p for p in IN_DIR.glob(\"*.csv\") if p.is_file()])\n",
        "if not files:\n",
        "    raise SystemExit(f\"No se encontraron CSV en {IN_DIR.resolve()}\")\n",
        "\n",
        "parts = []\n",
        "for p in files:\n",
        "    df = pd.read_csv(p)\n",
        "    parts.append(df)\n",
        "\n",
        "long_df = pd.concat(parts, ignore_index=True)\n",
        "\n",
        "# ========= 2) NORMALIZAR TIEMPO =========\n",
        "# Preferimos datetime_utc si existe y trae datos; si no, usamos time_start (ms)\n",
        "if \"datetime_utc\" in long_df.columns and long_df[\"datetime_utc\"].notna().any():\n",
        "    long_df[\"datetime_utc\"] = pd.to_datetime(long_df[\"datetime_utc\"], errors=\"coerce\", utc=True)\n",
        "else:\n",
        "    if \"time_start\" not in long_df.columns:\n",
        "        raise SystemExit(\"No hay columnas 'datetime_utc' ni 'time_start' en los CSV.\")\n",
        "    long_df[\"datetime_utc\"] = pd.to_datetime(long_df[\"time_start\"], unit=\"ms\", utc=True)\n",
        "\n",
        "# Renombrar estaciones si hace falta (GIR-EPM -> V-GIR-EPM)\n",
        "if \"name\" not in long_df.columns:\n",
        "    raise SystemExit(\"No se encontró la columna 'name' (estación) en los CSV.\")\n",
        "long_df[\"name\"] = long_df[\"name\"].map(lambda s: STATION_RENAME.get(s, s))\n",
        "\n",
        "# ========= 3) LIMPIEZA Y AGREGACIÓN BÁSICA =========\n",
        "# Asegurar numeric de las variables\n",
        "for c in VARS:\n",
        "    if c in long_df.columns:\n",
        "        long_df[c] = pd.to_numeric(long_df[c], errors=\"coerce\")\n",
        "\n",
        "# Nos quedamos con lo necesario\n",
        "keep_cols = [\"name\",\"datetime_utc\"] + [c for c in VARS if c in long_df.columns]\n",
        "long_df = long_df[keep_cols].dropna(subset=[\"datetime_utc\"]).copy()\n",
        "\n",
        "# Si hay duplicados (name, datetime_utc) promediamos\n",
        "agg_dict = {v: \"mean\" for v in VARS if v in long_df.columns}\n",
        "long_df = (long_df\n",
        "           .groupby([\"datetime_utc\",\"name\"], as_index=False, sort=True)\n",
        "           .agg(agg_dict)\n",
        "           .sort_values([\"name\",\"datetime_utc\"])\n",
        "           .reset_index(drop=True))\n",
        "\n",
        "# ========= 4) CONSTRUIR MATRIZ (index=tiempo, columnas=(estación, variable)) =========\n",
        "all_ts = long_df[\"datetime_utc\"].dropna().sort_values().unique()\n",
        "wide = pd.DataFrame(index=pd.DatetimeIndex(all_ts))\n",
        "\n",
        "# rellenar en el orden solicitado\n",
        "for st in stations_order_final:\n",
        "    sdf = long_df[long_df[\"name\"] == st].set_index(\"datetime_utc\").sort_index()\n",
        "    for lab in labels_order:\n",
        "        col = label_to_col[lab]\n",
        "        series = sdf[col].reindex(wide.index) if col in sdf.columns else pd.Series(index=wide.index, dtype=\"float64\")\n",
        "        wide[(st, lab)] = series\n",
        "\n",
        "# asegurar orden exacto de columnas\n",
        "wide = wide.reindex(columns=pd.MultiIndex.from_product([stations_order_final, labels_order]), copy=False)\n",
        "\n",
        "# ========= 5) EXPORTAR CON DOBLE ENCABEZADO PERSONALIZADO =========\n",
        "out_csv = OUT_DIR / \"era5_SO2_hourly_custom_header_2021-01-01_2025-02-28.csv\"\n",
        "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Filas 1 y 2 del encabezado\n",
        "row1 = [\"est\"] + [st for st in stations_order_final for _ in labels_order]\n",
        "row2 = [\"\"]    + [lab for _ in stations_order_final for lab in labels_order]\n",
        "\n",
        "# Escribir CSV\n",
        "with out_csv.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    # encabezados\n",
        "    f.write(\",\".join(row1) + \"\\n\")\n",
        "    f.write(\",\".join(row2) + \"\\n\")\n",
        "    # datos (datetime en America/Bogota)\n",
        "    for ts, row in wide.iterrows():\n",
        "        ts_str = ts.tz_convert(\"America/Bogota\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        vals = []\n",
        "        for st in stations_order_final:\n",
        "            for lab in labels_order:\n",
        "                v = row[(st, lab)]\n",
        "                vals.append(\"\" if pd.isna(v) else f\"{v:.3f}\".rstrip(\"0\").rstrip(\".\"))\n",
        "        f.write(\",\".join([ts_str] + vals) + \"\\n\")\n",
        "\n",
        "print(\"✔ CSV generado:\", out_csv.resolve())\n",
        "print(\"shape:\", (len(wide.index), len(row1)-1), \"| filas (horas) x columnas (estación*variable)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8865bc33",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name                                   datetime_utc           datetime_bogota  \\\n",
            "datetime_utc                                                                    \n",
            "2021-01-01 00:00:00+00:00  2021-01-01 00:00:00+0000  2020-12-31 19:00:00-0500   \n",
            "2021-01-01 01:00:00+00:00  2021-01-01 01:00:00+0000  2020-12-31 20:00:00-0500   \n",
            "2021-01-01 02:00:00+00:00  2021-01-01 02:00:00+0000  2020-12-31 21:00:00-0500   \n",
            "2021-01-01 03:00:00+00:00  2021-01-01 03:00:00+0000  2020-12-31 22:00:00-0500   \n",
            "2021-01-01 04:00:00+00:00  2021-01-01 04:00:00+0000  2020-12-31 23:00:00-0500   \n",
            "\n",
            "name                        CEN-TRAF    GIR-EPM   ITA-CJUS   MED-FISC  \n",
            "datetime_utc                                                           \n",
            "2021-01-01 00:00:00+00:00  16.558725  15.757944  15.599741  16.558725  \n",
            "2021-01-01 01:00:00+00:00  15.368188  14.704126  14.686548  15.368188  \n",
            "2021-01-01 02:00:00+00:00  14.764734  14.006921  14.071375  14.764734  \n",
            "2021-01-01 03:00:00+00:00  14.629373  13.519998  13.830545  14.629373  \n",
            "2021-01-01 04:00:00+00:00  14.363641  13.703485  13.402704  14.363641  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "# Ruta donde pusiste los CSV descargados\n",
        "IN_DIR = Path(\"era5_exports\")\n",
        "dfs = [pd.read_csv(p) for p in sorted(IN_DIR.glob(\"era5_t2m_hourly_*.csv\"))]\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Normaliza tiempo (UTC preferido)\n",
        "if df[\"datetime_utc\"].notna().any():\n",
        "    dt_utc = pd.to_datetime(df[\"datetime_utc\"], format=\"%Y-%m-%d %H:%M\", errors=\"coerce\", utc=True)\n",
        "elif \"date\" in df.columns and df[\"date\"].notna().any():\n",
        "    dt_utc = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\", errors=\"coerce\", utc=True)\n",
        "else:\n",
        "    dt_utc = pd.to_datetime(df[\"time_start\"], unit=\"ms\", utc=True)\n",
        "\n",
        "df[\"datetime_utc\"]   = dt_utc\n",
        "df[\"datetime_bogota\"] = df[\"datetime_utc\"].dt.tz_convert(\"America/Bogota\")\n",
        "\n",
        "wide = (\n",
        "    df.pivot_table(index=\"datetime_utc\", columns=\"name\", values=\"t2m_c\", aggfunc=\"mean\")\n",
        "      .sort_index()\n",
        ")\n",
        "out = wide.copy()\n",
        "out.insert(0, \"datetime_bogota\", out.index.tz_convert(\"America/Bogota\"))\n",
        "out.insert(0, \"datetime_utc\", out.index)\n",
        "\n",
        "out[\"datetime_utc\"] = out[\"datetime_utc\"].dt.strftime(\"%Y-%m-%d %H:%M:%S%z\").str.replace(r\"(\\+00:00)$\",\"Z\", regex=True)\n",
        "out[\"datetime_bogota\"] = pd.to_datetime(out[\"datetime_bogota\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
        "\n",
        "Path(\"data/raw/era5\").mkdir(parents=True, exist_ok=True)\n",
        "out.to_csv(\"data/raw/era5/era5_t2m_hourly_2021-01-01_2025-02-28_wide.csv\", index=False)\n",
        "print(out.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b600d94c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dewpoint_temperature_2m', 'temperature_2m', 'skin_temperature', 'soil_temperature_level_1', 'soil_temperature_level_2', 'soil_temperature_level_3', 'soil_temperature_level_4', 'lake_bottom_temperature', 'lake_ice_depth', 'lake_ice_temperature', 'lake_mix_layer_depth', 'lake_mix_layer_temperature', 'lake_shape_factor', 'lake_total_layer_temperature', 'snow_albedo', 'snow_cover', 'snow_density', 'snow_depth', 'snow_depth_water_equivalent', 'snowfall', 'snowmelt', 'temperature_of_snow_layer', 'skin_reservoir_content', 'volumetric_soil_water_layer_1', 'volumetric_soil_water_layer_2', 'volumetric_soil_water_layer_3', 'volumetric_soil_water_layer_4', 'forecast_albedo', 'surface_latent_heat_flux', 'surface_net_solar_radiation', 'surface_net_thermal_radiation', 'surface_sensible_heat_flux', 'surface_solar_radiation_downwards', 'surface_thermal_radiation_downwards', 'evaporation_from_bare_soil', 'evaporation_from_open_water_surfaces_excluding_oceans', 'evaporation_from_the_top_of_canopy', 'evaporation_from_vegetation_transpiration', 'potential_evaporation', 'runoff', 'snow_evaporation', 'sub_surface_runoff', 'surface_runoff', 'total_evaporation', 'u_component_of_wind_10m', 'v_component_of_wind_10m', 'surface_pressure', 'total_precipitation', 'leaf_area_index_high_vegetation', 'leaf_area_index_low_vegetation', 'snowfall_hourly', 'snowmelt_hourly', 'surface_latent_heat_flux_hourly', 'surface_net_solar_radiation_hourly', 'surface_net_thermal_radiation_hourly', 'surface_sensible_heat_flux_hourly', 'surface_solar_radiation_downwards_hourly', 'surface_thermal_radiation_downwards_hourly', 'evaporation_from_bare_soil_hourly', 'evaporation_from_open_water_surfaces_excluding_oceans_hourly', 'evaporation_from_the_top_of_canopy_hourly', 'evaporation_from_vegetation_transpiration_hourly', 'potential_evaporation_hourly', 'runoff_hourly', 'snow_evaporation_hourly', 'sub_surface_runoff_hourly', 'surface_runoff_hourly', 'total_evaporation_hourly', 'total_precipitation_hourly']\n"
          ]
        }
      ],
      "source": [
        "ic = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\")\n",
        "first = ic.first()\n",
        "print(first.bandNames().getInfo())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Documentación rápida\n",
        "- **Dataset**: `ECMWF/ERA5_LAND/HOURLY` (t2m en Kelvin → convertimos a **°C**).\n",
        "- **AGG**:\n",
        "  - `hourly`: mantiene las horas originales.\n",
        "  - `daily`: promedia por día con `mean()` en GEE.\n",
        "- **`sampleRegions`**: toma el valor del píxel ERA5‑Land (~9 km) más cercano al punto.\n",
        "- **Tiempo**: el dataset está en **UTC**. Se agrega `datetime_local` en **America/Bogota**.\n",
        "- **Salida**: `era5land_t2m_points.csv` con columnas (`name, lat, lon, date/datetime_utc, datetime_local, t2m_c`).\n",
        "\n",
        "### Cambios típicos\n",
        "- Añadir más ubicaciones a `LOCATIONS`.\n",
        "- Cambiar `DATE_START`, `DATE_END` y `AGG`.\n",
        "- Reemplazar `scale=10000` por otro valor si prefieres muestreo a una escala ligeramente distinta.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
